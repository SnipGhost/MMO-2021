{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №6\n",
    "## Классификация текста.\n",
    "\n",
    "Набор данных - [20 newsgroups text dataset](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset)\n",
    "\n",
    "Классы: 20  \n",
    "Выборка: 18846\n",
    "\n",
    "## Install\n",
    "\n",
    "```bash\n",
    "pip3 install gensim\n",
    "pip3 install spacy\n",
    "python3 -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "## Задание:\n",
    "\n",
    "Для произвольного набора данных, предназначенного для классификации текстов, решите задачу классификации текста двумя способами:\n",
    "\n",
    "- Способ 1. На основе CountVectorizer или TfidfVectorizer.\n",
    "- Способ 2. На основе моделей word2vec или Glove или fastText.\n",
    "- Сравните качество полученных моделей.\n",
    "\n",
    "Для поиска наборов данных в поисковой системе можно использовать ключевые слова \"datasets for text classification\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk import tokenize\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/snipghost/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"sci.crypt\", \"sci.electronics\", \"talk.religion.misc\"]\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, frequency = np.unique(newsgroups_train.target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: 0, count: 595\n",
      "value: 1, count: 591\n",
      "value: 2, count: 377\n"
     ]
    }
   ],
   "source": [
    "for l, f in zip(unique, frequency):\n",
    "    print(f'value: {l}, count: {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snipghost/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "nltk.download('stopwords')\n",
    "stopwords_eng = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(t):\n",
    "    # t = ' '.join([i.strip().lower() for i in t.split(' ')])\n",
    "    t = re.sub(r'[^a-zA-Z0-9 \\n]', '', t)\n",
    "    t = re.sub('\\s+', ' ', t)\n",
    "    t = ' '.join([token.lemma_.lower() for token in nlp(t) if token not in stopwords_eng])\n",
    "    return t\n",
    "\n",
    "texts = newsgroups_train.data\n",
    "texts_array = []\n",
    "\n",
    "for text in texts:\n",
    "    prepared_text = prepare(text)\n",
    "    texts_array.append(prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563 from mhaldlynxdacnortheasternedu mark hald subject re dayton hamfest organization northeastern university boston ma 02115 usa distribution usa lines 13 i book a hotel red roof inn last week in cincinnati blue ash which be at the northern tip of the metro cincy area i choose it for a few reason 1 all hotel in and near dayton be book solid 2 this hotel be only cost 28night 3 it be one of about 4 room leave on the night i reserve 4 cincinnati probably have more to to at night than dayton i intend to hit the riverboat entertainment at dusk if anyone have other suggestion for nightlife please let i know of other hot spot thanks mark\n"
     ]
    }
   ],
   "source": [
    "print(len(texts_array), texts_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = newsgroups_test.data\n",
    "test_texts_arr = []\n",
    "\n",
    "for text in test_texts:\n",
    "    prepared_text = prepare(text)\n",
    "    test_texts_arr.append(prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040 from markkcypresswestsuncom mark kampe subject re cybele and transgendersexualism organization sunsoft south lines 29 distribution world replyto markkcypresswestsuncom nntppostinghost sagredo in article 260493115730ravenaimsuncedu fhuntmeduncedu freb hunt write be there some relation between the name cybele and the phenemenon of the sibyl your paragraph above seem to indicate there might be the oed give the etymology of sibyl as come from the ancient greek sigma iota beta upsilon lambda lambda alpha s i b ih l l a which be claim to come from the doric sigma iota omicron beta upsilon lambda lambda alpha s i o b ih l l a which if i read it properly in turn come from the attican athenian theta epsilon omicron beta omicron upsilon lambda eta th eh o b o ih l ae i do nt know much about attis but it would nt surprise i to learn that this god be tie to the athenian capital alpha tau tau iota kappa upsilon sigma a t t i k u s the oed do not list any etymology for cybele since that be a propper noun but i suggest that the greek spelling of that word would be much close to the anticedant of sibyl than the two word be now perhaps cybele be a french or latin spelling\n"
     ]
    }
   ],
   "source": [
    "print(len(test_texts_arr), test_texts_arr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Способ 1.\n",
    "\n",
    "TF-IDF + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_feature_matrix_tfidf = tfidf_vectorizer.fit_transform(texts_array)\n",
    "test_feature_matrix__tfidf = tfidf_vectorizer.transform(test_texts_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "train_feature_matrix_count = count_vectorizer.fit_transform(texts_array)\n",
    "test_feature_matrix_count = count_vectorizer.transform(test_texts_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values_train = newsgroups_train.target\n",
    "target_values_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tfidf = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors': [2, 3, 5, 7, 9, 11]}\n",
    "\n",
    "knn_tfidf_grid = GridSearchCV(knn_tfidf, parameters, scoring='balanced_accuracy', verbose=4, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.714, total=   0.1s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.715, total=   0.1s\n",
      "[CV] n_neighbors=2 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_neighbors=2, score=0.722, total=   0.1s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.703, total=   0.1s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.709, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_neighbors=3, score=0.764, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.759, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.727, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.710, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.752, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.758, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.759, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.721, total=   0.2s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.736, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.723, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.711, total=   0.1s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.715, total=   0.1s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.730, total=   0.1s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.706, total=   0.1s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.724, total=   0.1s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.702, total=   0.1s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.716, total=   0.1s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.720, total=   0.1s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.680, total=   0.1s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.716, total=   0.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.651, total=   0.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.701, total=   0.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.706, total=   0.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.673, total=   0.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.713, total=   0.1s\n",
      "best param of n_neighbors 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83       396\n",
      "           1       0.97      0.68      0.80       393\n",
      "           2       0.89      0.87      0.88       251\n",
      "\n",
      "    accuracy                           0.83      1040\n",
      "   macro avg       0.86      0.84      0.84      1040\n",
      "weighted avg       0.86      0.83      0.83      1040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_tfidf_grid.fit(train_feature_matrix_count, target_values_train)\n",
    "\n",
    "print('best param of n_neighbors', knn_count_grid.best_params_['n_neighbors'])\n",
    "best_knn_tfidf = KNeighborsClassifier(n_neighbors=knn_count_grid.best_params_['n_neighbors'])\n",
    "\n",
    "best_knn_tfidf.fit(train_feature_matrix_tfidf, target_values_train)\n",
    "best_pred_knn = best_knn_tfidf.predict(test_feature_matrix__tfidf)\n",
    "\n",
    "print(classification_report(target_values_test, best_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_count = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors': [2, 3, 5, 7, 9, 11]}\n",
    "\n",
    "knn_count_grid = GridSearchCV(knn_count, parameters, scoring='balanced_accuracy', verbose=4, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.714, total=   0.1s\n",
      "[CV] n_neighbors=2 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_neighbors=2, score=0.715, total=   0.1s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.722, total=   0.1s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] ....................... n_neighbors=2, score=0.703, total=   0.1s\n",
      "[CV] n_neighbors=2 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_neighbors=2, score=0.709, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.764, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.759, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.727, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.710, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.752, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.758, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.759, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.721, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.736, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.723, total=   0.1s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.711, total=   0.1s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.715, total=   0.1s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.730, total=   0.1s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.706, total=   0.2s\n",
      "[CV] n_neighbors=7 ...................................................\n",
      "[CV] ....................... n_neighbors=7, score=0.724, total=   0.1s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.702, total=   0.1s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.716, total=   0.1s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.720, total=   0.1s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.680, total=   0.2s\n",
      "[CV] n_neighbors=9 ...................................................\n",
      "[CV] ....................... n_neighbors=9, score=0.716, total=   0.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.651, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.701, total=   0.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.706, total=   0.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.673, total=   0.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ...................... n_neighbors=11, score=0.713, total=   0.1s\n",
      "best param of n_neighbors 3\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66       396\n",
      "           1       0.67      0.61      0.64       393\n",
      "           2       0.73      0.57      0.64       251\n",
      "\n",
      "    accuracy                           0.65      1040\n",
      "   macro avg       0.67      0.64      0.65      1040\n",
      "weighted avg       0.66      0.65      0.65      1040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_count_grid.fit(train_feature_matrix_count, target_values_train)\n",
    "\n",
    "print('best param of n_neighbors', knn_count_grid.best_params_['n_neighbors'])\n",
    "best_knn_count = KNeighborsClassifier(n_neighbors=knn_count_grid.best_params_['n_neighbors'])\n",
    "print(best_knn_count)\n",
    "best_knn_count.fit(train_feature_matrix_count, target_values_train)\n",
    "best_knn_pred_count = best_knn_count.predict(test_feature_matrix_count)\n",
    "\n",
    "print(classification_report(target_values_test, best_knn_pred_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Способ 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/snipghost/opt/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "gensim.downloader.info()\n",
    "# glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveTokenizer:\n",
    "    def __init__(self, glove_tokenizer):\n",
    "        self.glove = glove_tokenizer\n",
    "        self.token_length = 800\n",
    "        self.embedding_size = 50\n",
    "\n",
    "    def __getitem__(self, word):\n",
    "        try:\n",
    "            vector = glove_vectors.get_vector(word).reshape(1, self.embedding_size)\n",
    "        except KeyError as e:\n",
    "            vector = np.zeros((1, self.embedding_size))\n",
    "        return vector\n",
    "\n",
    "\n",
    "    def __padd(self, sentence):\n",
    "        padded_sentence = np.zeros((self.token_length, self.embedding_size))\n",
    "        for i, token in enumerate(sentence):\n",
    "            padded_sentence[i] = token\n",
    "        return padded_sentence\n",
    "  \n",
    "    def tokenize(self, sentence):\n",
    "        encoded_sentence = []\n",
    "        sentence = sentence.strip(' ').split(' ')\n",
    "        for i in sentence:\n",
    "            token = self.__getitem__(i)\n",
    "            encoded_sentence.append(token)    \n",
    "        return np.array(self.__padd(encoded_sentence), dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GloveTokenizer(glove_vectors)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 index 800 is out of bounds for axis 0 with size 800\n",
      "47 index 800 is out of bounds for axis 0 with size 800\n",
      "186 index 800 is out of bounds for axis 0 with size 800\n",
      "204 index 800 is out of bounds for axis 0 with size 800\n",
      "211 index 800 is out of bounds for axis 0 with size 800\n",
      "214 index 800 is out of bounds for axis 0 with size 800\n",
      "261 index 800 is out of bounds for axis 0 with size 800\n",
      "279 index 800 is out of bounds for axis 0 with size 800\n",
      "313 index 800 is out of bounds for axis 0 with size 800\n",
      "318 index 800 is out of bounds for axis 0 with size 800\n",
      "330 index 800 is out of bounds for axis 0 with size 800\n",
      "334 index 800 is out of bounds for axis 0 with size 800\n",
      "355 index 800 is out of bounds for axis 0 with size 800\n",
      "372 index 800 is out of bounds for axis 0 with size 800\n",
      "389 index 800 is out of bounds for axis 0 with size 800\n",
      "405 index 800 is out of bounds for axis 0 with size 800\n",
      "418 index 800 is out of bounds for axis 0 with size 800\n",
      "420 index 800 is out of bounds for axis 0 with size 800\n",
      "425 index 800 is out of bounds for axis 0 with size 800\n",
      "442 index 800 is out of bounds for axis 0 with size 800\n",
      "446 index 800 is out of bounds for axis 0 with size 800\n",
      "457 index 800 is out of bounds for axis 0 with size 800\n",
      "463 index 800 is out of bounds for axis 0 with size 800\n",
      "485 index 800 is out of bounds for axis 0 with size 800\n",
      "549 index 800 is out of bounds for axis 0 with size 800\n",
      "585 index 800 is out of bounds for axis 0 with size 800\n",
      "637 index 800 is out of bounds for axis 0 with size 800\n",
      "640 index 800 is out of bounds for axis 0 with size 800\n",
      "654 index 800 is out of bounds for axis 0 with size 800\n",
      "655 index 800 is out of bounds for axis 0 with size 800\n",
      "670 index 800 is out of bounds for axis 0 with size 800\n",
      "697 index 800 is out of bounds for axis 0 with size 800\n",
      "703 index 800 is out of bounds for axis 0 with size 800\n",
      "747 index 800 is out of bounds for axis 0 with size 800\n",
      "755 index 800 is out of bounds for axis 0 with size 800\n",
      "756 index 800 is out of bounds for axis 0 with size 800\n",
      "758 index 800 is out of bounds for axis 0 with size 800\n",
      "820 index 800 is out of bounds for axis 0 with size 800\n",
      "834 index 800 is out of bounds for axis 0 with size 800\n",
      "877 index 800 is out of bounds for axis 0 with size 800\n",
      "892 index 800 is out of bounds for axis 0 with size 800\n",
      "906 index 800 is out of bounds for axis 0 with size 800\n",
      "949 index 800 is out of bounds for axis 0 with size 800\n",
      "955 index 800 is out of bounds for axis 0 with size 800\n",
      "959 index 800 is out of bounds for axis 0 with size 800\n",
      "979 index 800 is out of bounds for axis 0 with size 800\n",
      "985 index 800 is out of bounds for axis 0 with size 800\n",
      "1041 index 800 is out of bounds for axis 0 with size 800\n",
      "1115 index 800 is out of bounds for axis 0 with size 800\n",
      "1120 index 800 is out of bounds for axis 0 with size 800\n",
      "1122 index 800 is out of bounds for axis 0 with size 800\n",
      "1124 index 800 is out of bounds for axis 0 with size 800\n",
      "1125 index 800 is out of bounds for axis 0 with size 800\n",
      "1138 index 800 is out of bounds for axis 0 with size 800\n",
      "1140 index 800 is out of bounds for axis 0 with size 800\n",
      "1150 index 800 is out of bounds for axis 0 with size 800\n",
      "1153 index 800 is out of bounds for axis 0 with size 800\n",
      "1165 index 800 is out of bounds for axis 0 with size 800\n",
      "1185 index 800 is out of bounds for axis 0 with size 800\n",
      "1186 index 800 is out of bounds for axis 0 with size 800\n",
      "1191 index 800 is out of bounds for axis 0 with size 800\n",
      "1201 index 800 is out of bounds for axis 0 with size 800\n",
      "1209 index 800 is out of bounds for axis 0 with size 800\n",
      "1260 index 800 is out of bounds for axis 0 with size 800\n",
      "1262 index 800 is out of bounds for axis 0 with size 800\n",
      "1295 index 800 is out of bounds for axis 0 with size 800\n",
      "1321 index 800 is out of bounds for axis 0 with size 800\n",
      "1339 index 800 is out of bounds for axis 0 with size 800\n",
      "1426 index 800 is out of bounds for axis 0 with size 800\n",
      "1489 index 800 is out of bounds for axis 0 with size 800\n",
      "1502 index 800 is out of bounds for axis 0 with size 800\n",
      "1545 index 800 is out of bounds for axis 0 with size 800\n",
      "1551 index 800 is out of bounds for axis 0 with size 800\n",
      "1561 index 800 is out of bounds for axis 0 with size 800\n",
      "(1489, 800, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1489, 40000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare(t):\n",
    "    # t = ' '.join([i.strip().lower() for i in t.split(' ')])\n",
    "    t = re.sub(r'[^a-zA-Z0-9 ]', '', t)\n",
    "    t = re.sub('\\s+', ' ', t)\n",
    "    lemmas = [token.lemma_.lower() for token in nlp(t) if token not in stopwords_eng]\n",
    "    t = ' '.join(lemmas)\n",
    "    vectors = tokenizer.tokenize(t)\n",
    "    return vectors, len(lemmas)\n",
    "\n",
    "vectors_array_train = []\n",
    "labels_train = []\n",
    "\n",
    "for enum, text, label in zip(range(len(newsgroups_train.data)), newsgroups_train.data, newsgroups_train.target):\n",
    "    try:\n",
    "        vector, length = prepare(text)\n",
    "        # print(vector, vector.shape)\n",
    "        vectors_array_train.append(vector)\n",
    "        labels_train.append(label)\n",
    "    except IndexError as e:\n",
    "        print(enum, e)\n",
    "        continue\n",
    "\n",
    "\n",
    "vectors_array_train = np.array(vectors_array_train)\n",
    "print(vectors_array_train.shape)\n",
    "train_data = vectors_array_train.reshape((-1, vectors_array_train.shape[1]*vectors_array_train.shape[2]))\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 index 800 is out of bounds for axis 0 with size 800\n",
      "56 index 800 is out of bounds for axis 0 with size 800\n",
      "69 index 800 is out of bounds for axis 0 with size 800\n",
      "106 index 800 is out of bounds for axis 0 with size 800\n",
      "122 index 800 is out of bounds for axis 0 with size 800\n",
      "184 index 800 is out of bounds for axis 0 with size 800\n",
      "282 index 800 is out of bounds for axis 0 with size 800\n",
      "286 index 800 is out of bounds for axis 0 with size 800\n",
      "341 index 800 is out of bounds for axis 0 with size 800\n",
      "376 index 800 is out of bounds for axis 0 with size 800\n",
      "402 index 800 is out of bounds for axis 0 with size 800\n",
      "439 index 800 is out of bounds for axis 0 with size 800\n",
      "455 index 800 is out of bounds for axis 0 with size 800\n",
      "459 index 800 is out of bounds for axis 0 with size 800\n",
      "505 index 800 is out of bounds for axis 0 with size 800\n",
      "613 index 800 is out of bounds for axis 0 with size 800\n",
      "651 index 800 is out of bounds for axis 0 with size 800\n",
      "668 index 800 is out of bounds for axis 0 with size 800\n",
      "794 index 800 is out of bounds for axis 0 with size 800\n",
      "808 index 800 is out of bounds for axis 0 with size 800\n",
      "884 index 800 is out of bounds for axis 0 with size 800\n",
      "997 index 800 is out of bounds for axis 0 with size 800\n",
      "999 index 800 is out of bounds for axis 0 with size 800\n",
      "1027 index 800 is out of bounds for axis 0 with size 800\n",
      "1034 index 800 is out of bounds for axis 0 with size 800\n"
     ]
    }
   ],
   "source": [
    "vectors_array_test = []\n",
    "labels_test= []\n",
    "\n",
    "for enum, text, label in zip(range(len(newsgroups_test.data)), newsgroups_test.data, newsgroups_test.target):\n",
    "    try:\n",
    "        vector, length = prepare(text)\n",
    "        vectors_array_test.append(vector)\n",
    "        labels_test.append(label)\n",
    "    except IndexError as e:\n",
    "        print(enum, e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1015, 40000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_array_test = np.array(vectors_array_test)\n",
    "test_data = vectors_array_test.reshape((-1, vectors_array_test.shape[1]*vectors_array_test.shape[2]))\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:  4.7min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param of n_neighbors 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "glove_knn_clf = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors': [2, 3, 5, 7, 9]}\n",
    "\n",
    "glove_clf_grid = GridSearchCV(glove_knn_clf, parameters, verbose=4, cv=3,\n",
    "                            scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "glove_clf_grid.fit(train_data, labels_train)\n",
    "\n",
    "print('best param of n_neighbors', glove_clf_grid.best_params_['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.54      0.51       316\n",
      "           1       0.53      0.50      0.51       305\n",
      "           2       0.48      0.42      0.45       179\n",
      "\n",
      "    accuracy                           0.50       800\n",
      "   macro avg       0.50      0.49      0.49       800\n",
      "weighted avg       0.50      0.50      0.50       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_glove_knn = KNeighborsClassifier(n_neighbors=glove_clf_grid.best_params_['n_neighbors'])\n",
    "best_glove_knn.fit(train_data, labels_train)\n",
    "best_pred_glove_knn = best_glove_knn.predict(test_data[:800])\n",
    "\n",
    "print(classification_report(labels_test[:800], best_pred_glove_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
